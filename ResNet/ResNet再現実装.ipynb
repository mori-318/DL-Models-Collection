{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77c6419",
   "metadata": {},
   "source": [
    "# ResNetを再現実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93d87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/mori/dev/DL-Models-Collection/ResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d5726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_ch, out_ch, stride=1, padding=1):\n",
    "    \"\"\"3x3の畳み込み\"\"\"\n",
    "    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=padding, bias=False)\n",
    "\n",
    "def pad_channels(x, out_ch):\n",
    "    \"\"\"チャンネル数を合わせる\"\"\"\n",
    "    pad_ch = out_ch - x.size(1)\n",
    "    if pad_ch <= 0: return x\n",
    "    return torch.cat([x, x.new_zeros(x.size(0), pad_ch, *x.shape[2:])], dim=1)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    BasicBlock\n",
    "    2層の畳み込みの後にショートカットを足す\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(in_ch, out_ch, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = conv3x3(out_ch, out_ch)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        # 入力と出力のチャンネル数を合わせるために、ストライドで間引き & ゼロチャンネルで埋める\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            # オプションAのショートカット\n",
    "            self.shortcut = (lambda x: pad_channels(x[:, :, ::stride, ::stride], out_ch))\n",
    "        else:\n",
    "            self.shortcut = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet20(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet20\n",
    "    入力画像のサイズは32x32\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_ch = 16\n",
    "\n",
    "        self.conv1 = conv3x3(3, self.in_ch)  # 1層目\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_ch)\n",
    "        self.layer1 = self._make_layer(out_ch=16, blocks=3, stride=1)  # 2~7層目\n",
    "        self.layer2 = self._make_layer(out_ch=32, blocks=3, stride=2)  # 8~13層目\n",
    "        self.layer3 = self._make_layer(out_ch=64, blocks=3, stride=2)  # 14~19層目\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)  # 20層目\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _make_layer(self, out_ch, blocks, stride):\n",
    "        \"\"\"\n",
    "        BasicBlockをblocks回重ねた層を作成\n",
    "        Args:\n",
    "            out_ch (int): 出力チャンネル数\n",
    "            blocks (int): BasicBlockを重ねる数\n",
    "            stride (int): 畳み込みのストライド\n",
    "        \"\"\"\n",
    "        layers = [BasicBlock(self.in_ch, out_ch, stride)]\n",
    "        self.in_ch = out_ch\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_ch, out_ch))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666eebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# ダミー入力で動作確認\n",
    "resnet20 = ResNet20()\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "output = resnet20(dummy_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bc2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer count: 20\n"
     ]
    }
   ],
   "source": [
    "# 層数が20レイヤーか確認\n",
    "def count_layers(model):\n",
    "    count = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Layer count:\", count_layers(resnet20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9765ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 0.27M\n"
     ]
    }
   ],
   "source": [
    "# パラメータ数を確認\n",
    "total_params = sum(p.numel() for p in resnet20.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55fba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "        BasicBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-19           [-1, 32, 16, 16]              64\n",
      "           Conv2d-20           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-22           [-1, 32, 16, 16]               0\n",
      "           Conv2d-23           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-24           [-1, 32, 16, 16]              64\n",
      "           Conv2d-25           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-26           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-27           [-1, 32, 16, 16]               0\n",
      "           Conv2d-28           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-29           [-1, 32, 16, 16]              64\n",
      "           Conv2d-30           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-31           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-32           [-1, 32, 16, 16]               0\n",
      "           Conv2d-33             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-34             [-1, 64, 8, 8]             128\n",
      "           Conv2d-35             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-36             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-37             [-1, 64, 8, 8]               0\n",
      "           Conv2d-38             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-39             [-1, 64, 8, 8]             128\n",
      "           Conv2d-40             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-41             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-42             [-1, 64, 8, 8]               0\n",
      "           Conv2d-43             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-44             [-1, 64, 8, 8]             128\n",
      "           Conv2d-45             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-46             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-47             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48             [-1, 64, 1, 1]               0\n",
      "           Linear-49                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 269,722\n",
      "Trainable params: 269,722\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.53\n",
      "Params size (MB): 1.03\n",
      "Estimated Total Size (MB): 4.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torchsummaryでもアーキテクチャとパラメータ数を確認してみる\n",
    "summary(resnet20, (3, 32, 32), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f215ec5",
   "metadata": {},
   "source": [
    "### CIFAR-10の読み込み & 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ed9bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10データセットのダウンロード\n",
    "x_train = np.load(os.path.join(BASE_DIR, 'data', 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(BASE_DIR, 'data', 'y_train.npy'))\n",
    "x_test = np.load(os.path.join(BASE_DIR, 'data', 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(BASE_DIR, 'data', 'y_test.npy'))\n",
    "\n",
    "# 形状の確認\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b73b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\" カスタムデータセットクラス \"\"\"\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        x = self.transform(x)\n",
    "        y = torch.as_tensor(y, dtype=torch.long)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# transform定義\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # NumPyをPILに変換\n",
    "    transforms.ToPILImage(),\n",
    "    # 各辺を4ピクセルのゼロパディングしたあとに32x32のランダムクロップ\n",
    "    transforms.RandomCrop((32, 32), padding=4),\n",
    "    # 50%の確率で水平反転\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # テンソルに変換\n",
    "    transforms.ToTensor(),\n",
    "    # 画像を標準化\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    # テンソルに変換\n",
    "    transforms.ToTensor(),\n",
    "    # 画像を標準化\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# データセット作成\n",
    "train_dataset = CustomDataset(x_train, y_train, transform=transform_train)\n",
    "test_dataset = CustomDataset(x_test, y_test, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954fafb",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676f0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerAndTester:\n",
    "    \"\"\"\n",
    "    モデル学習と誤差率での評価を行うクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, model, optimizer, max_iter, train_loader, test_loader, save_dir):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "        self.plot_save_path = os.path.join(save_dir, \"plot.png\")\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        log_dir = os.path.join(save_dir, \"logs\")\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "\n",
    "    def train(self):\n",
    "        current_iter = 0\n",
    "        pbar = tqdm(total=self.max_iter, desc=\"Training\")\n",
    "\n",
    "        try:\n",
    "            while current_iter < self.max_iter:\n",
    "                for images, labels in self.train_loader:\n",
    "                    # -------- forward / backward --------\n",
    "                    self.model.train()\n",
    "                    images = images.to(self.device, non_blocking=True)\n",
    "                    labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    # -------- bookkeeping --------\n",
    "                    current_iter += 1\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    # 4000iter ごとに誤差率を TensorBoard へ\n",
    "                    if current_iter % 4000 == 0:\n",
    "                        train_err = self.calc_error(self.train_loader)\n",
    "                        test_err  = self.calc_error(self.test_loader)\n",
    "\n",
    "                        # --- ★ ② ここで SummaryWriter ------------\n",
    "                        self.writer.add_scalars(\n",
    "                            main_tag=\"Error\",\n",
    "                            tag_scalar_dict={\n",
    "                                \"train_err\": train_err,\n",
    "                                \"test_err\": test_err,\n",
    "                            },\n",
    "                            global_step=current_iter,\n",
    "                        )\n",
    "                        self.writer.flush()\n",
    "                        # -----------------------------------------\n",
    "\n",
    "                        pbar.set_postfix(\n",
    "                            TrainErr=f\"{train_err:.4f}\",\n",
    "                            TestErr=f\"{test_err:.4f}\",\n",
    "                            LR=self.optimizer.param_groups[0]['lr']\n",
    "                        )\n",
    "\n",
    "                    # LR スケジューリング\n",
    "                    if current_iter in (32000, 48000):\n",
    "                        for g in self.optimizer.param_groups:\n",
    "                            g['lr'] *= 0.1\n",
    "\n",
    "                    # 所定回数に達したら終了\n",
    "                    if current_iter >= self.max_iter:\n",
    "                        break\n",
    "        finally:\n",
    "            pbar.close()\n",
    "            self.writer.close()   # --- ★ ③ 忘れずにクローズ\n",
    "            # 退出時にテスト誤差を返す\n",
    "        return self.calc_error(self.test_loader)\n",
    "\n",
    "    def calc_error(self, loader):\n",
    "        \"\"\"\n",
    "        渡されたデータローダーの誤差率を計算する\n",
    "        Args:\n",
    "            loader: データローダー\n",
    "        Returns:\n",
    "            float: 誤差率\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 正解数を計算\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images = images.to(self.device, non_blocking=True)\n",
    "                labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 誤差率を計算して返す\n",
    "        return (1 - correct / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402143d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 64000/64000 [28:41<00:00, 37.18it/s, LR=0.001, TestErr=8.7500, TrainErr=0.4460]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータでの最終誤差率: 8.750000000000002\n"
     ]
    }
   ],
   "source": [
    "# 学習率、バッチサイズ、イテレーション数設定\n",
    "lr         = 0.1\n",
    "batch_size = 128\n",
    "max_iter   = 64000\n",
    "\n",
    "# モデル設定\n",
    "model = ResNet20()\n",
    "\n",
    "# オプティマイザ設定\n",
    "bn_params, other_params = [], []\n",
    "for n,p in model.named_parameters():\n",
    "    (bn_params if 'bn' in n else other_params).append(p)\n",
    "\n",
    "# バッチ正規化パラメータにweight_decayを適用しないように設定\n",
    "optimizer = torch.optim.SGD(\n",
    "    [{'params': other_params , 'weight_decay':1e-4},\n",
    "    {'params': bn_params    , 'weight_decay':0.   }],\n",
    "    lr=lr, momentum=0.9\n",
    ")\n",
    "\n",
    "# データローダ作成\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 学習 & 評価\n",
    "save_dir = \"/home/mori/dev/DL-Models-Collection/ResNet\"\n",
    "last_err = TrainerAndTester(model, optimizer, max_iter, train_loader, test_loader, save_dir).train()\n",
    "print(f\"テストデータでの最終誤差率: {last_err}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
